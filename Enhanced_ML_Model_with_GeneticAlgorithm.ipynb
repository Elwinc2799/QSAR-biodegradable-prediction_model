{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GeneticAlgorithmMLModels.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ih34jQAduwle"
      },
      "source": [
        "Data uploading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "-3B7PQ8vuqKi",
        "outputId": "74fe555c-1fec-4f78-f200-c09285858bd4"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-d87f0cb4-503f-43f4-85c5-9678df1ed6f1\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-d87f0cb4-503f-43f4-85c5-9678df1ed6f1\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving train.csv to train.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K3uwc1hWu2ip"
      },
      "source": [
        "Library loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Maucxtwbuycv",
        "outputId": "4bf7ef13-0cb3-40cd-9f3f-587941c36ff5"
      },
      "source": [
        "!pip install deap"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting deap\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/99/d1/803c7a387d8a7e6866160b1541307f88d534da4291572fb32f69d2548afb/deap-1.3.1-cp37-cp37m-manylinux2010_x86_64.whl (157kB)\n",
            "\r\u001b[K     |██                              | 10kB 16.5MB/s eta 0:00:01\r\u001b[K     |████▏                           | 20kB 20.4MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 30kB 23.5MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 40kB 26.7MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 51kB 29.3MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 61kB 29.2MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 71kB 29.1MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 81kB 29.4MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 92kB 30.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 102kB 30.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 112kB 30.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 122kB 30.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 133kB 30.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 143kB 30.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 153kB 30.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 163kB 30.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from deap) (1.19.5)\n",
            "Installing collected packages: deap\n",
            "Successfully installed deap-1.3.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xd_GPYn6u4t4"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random as rnd\n",
        "from sklearn.metrics import classification_report\n",
        "import io\n",
        "\n",
        "from deap import base\n",
        "from deap import creator\n",
        "from deap import tools\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from sklearn import preprocessing\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC, LinearSVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.linear_model import Perceptron\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import f_regression\n",
        "from sklearn.pipeline import make_pipeline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "XIqgAQsAu9dA",
        "outputId": "950752b0-a0be-4bb4-c435-eb5e6692ddc7"
      },
      "source": [
        "df = pd.read_csv(io.BytesIO(uploaded['biodeg.csv']), sep=';')\n",
        "df_name = df.columns\n",
        "df.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-46208f186d17>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muploaded\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'biodeg.csv'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m';'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'biodeg.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A4GdWaPfu__e"
      },
      "source": [
        "SEED = 42\n",
        "np.random.seed(SEED)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9OB58LKdcyNl"
      },
      "source": [
        "### Genetic Algorithm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y41aV5vRyOl8"
      },
      "source": [
        "columns = df.drop('experimental_class', axis=1).columns\n",
        "training = pd.concat([df])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zt_WDBNcvF9N"
      },
      "source": [
        "1. Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gMXpRR9avB5U"
      },
      "source": [
        "def getPenaltyLR():\n",
        "  penalties = ['l1', 'l2']\n",
        "  index = rnd.randint(0, len(penalties) - 1)   \n",
        "  penalty = penalties[index]\n",
        "\n",
        "  return penalty\n",
        "\n",
        "def getCLR():\n",
        "  r = rnd.random()\n",
        "  r2 = rnd.randint(0, 4)\n",
        "  C = r + r2 + 0.000000001 \n",
        "\n",
        "  return C\n",
        "\n",
        "def getMultiClassLR():\n",
        "  multi_classes = ['auto', 'ovr', 'multinomial']\n",
        "  index = rnd.randint(0, len(multi_classes) - 1)   \n",
        "  multi_class = multi_classes[index]\n",
        "\n",
        "  return multi_class"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KoV3JXYPwx5B"
      },
      "source": [
        "def getModelLR(individual):\n",
        "  penalty = individual[0]\n",
        "  C = individual[1]\n",
        "  multi_class = individual[2]\n",
        "\n",
        "  model = LogisticRegression(penalty=penalty, C=C, multi_class=multi_class)\n",
        "\n",
        "  return model\n",
        "\n",
        "def getXyLR(individual):\n",
        "  selected_columns = list(columns)\n",
        "\n",
        "  for i in range(len(individual[3:])):\n",
        "    if individual[3 + i] < 1:\n",
        "      selected_columns.remove(columns[i])\n",
        "\n",
        "  target_columns = np.append(['experimental_class'], selected_columns)\n",
        "  df = training.loc[:, target_columns].dropna()\n",
        "  X  = df.loc[:, selected_columns]\n",
        "  y = np.ravel(df.loc[:, ['experimental_class']])\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
        "  standard_scaler = preprocessing.StandardScaler().fit(X)\n",
        "  X_train = standard_scaler.transform(X_train)\n",
        "  X_test = standard_scaler.transform(X_test)\n",
        "  return [X_train, y_train, X_test, y_test, selected_columns, standard_scaler] \n",
        "\n",
        "def evaluteOneMaxLR(individual):\n",
        "  model = getModelLR(individual)\n",
        "  Xy = getXyLR(individual)\n",
        "  scores = cross_val_score(model, Xy[0], Xy[1], cv=5, n_jobs=-1)\n",
        "  mean = scores.mean(),\n",
        "  \n",
        "  return mean\n",
        "\n",
        "def myMutateLR(individual, indpb=0.05):\n",
        "  if rnd.random() < indpb:\n",
        "      individual[0] = toolbox.attribute_PenaltyLR()\n",
        "\n",
        "  if rnd.random() < indpb:\n",
        "      individual[1] = toolbox.attribute_CLR()\n",
        "\n",
        "  if rnd.random() < indpb:\n",
        "      individual[2] = toolbox.attribute_Multi_ClassLR()\n",
        "      \n",
        "  for i in range(len(individual[3:])):\n",
        "      if rnd.random() < indpb:\n",
        "          individual[3 + i] = toolbox.attribute_bool()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8KHw1olNwNbn"
      },
      "source": [
        "creator.create('FitnessMax', base.Fitness, weights=(1.0,))\n",
        "creator.create('Individual', list, fitness=creator.FitnessMax)\n",
        "\n",
        "toolbox = base.Toolbox()\n",
        "toolbox.register('attribute_bool', rnd.randint, 0, 1)\n",
        "toolbox.register('attribute_PenaltyLR', getPenaltyLR)\n",
        "toolbox.register('attribute_CLR', getCLR)\n",
        "toolbox.register('attribute_Multi_ClassLR', getMultiClassLR)\n",
        "\n",
        "function_sequence = [toolbox.attribute_PenaltyLR, toolbox.attribute_CLR, toolbox.attribute_Multi_ClassLR]\n",
        "\n",
        "for column in columns:\n",
        "  function_sequence.append(toolbox.attribute_bool)\n",
        "\n",
        "toolbox.register('individual', tools.initCycle, creator.Individual, function_sequence, 1)\n",
        "toolbox.register('population', tools.initRepeat, list, toolbox.individual)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGhQrkFwztTS"
      },
      "source": [
        "CXPB, MUTPB, NGEN, POPSIZE = 0.5, 0.2, 100, 100\n",
        "pop = toolbox.population(n=POPSIZE) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tbASD2fHy-pT"
      },
      "source": [
        "toolbox.register('evaluate', evaluteOneMaxLR)\n",
        "toolbox.register('mate', tools.cxTwoPoint)\n",
        "toolbox.register('mutate', myMutateLR, indpb=0.15)\n",
        "toolbox.register('select', tools.selTournament, tournsize=3)\n",
        "rnd.seed(66)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1HjMrAkIzyG8"
      },
      "source": [
        "print('Start evolution of Logistic Regression')\n",
        "\n",
        "fitnesses = list(map(toolbox.evaluate, pop))\n",
        "for individual, fitness in zip(pop, fitnesses):\n",
        "  individual.fitness.values = fitness\n",
        "\n",
        "print (f'  Evaluated {len(pop)} individuals')\n",
        "\n",
        "for generation in range(NGEN):\n",
        "  print(f'-- Generation {generation} --')\n",
        "\n",
        "  offspring = toolbox.select(pop, len(pop))\n",
        "  offspring = list(map(toolbox.clone, offspring))\n",
        "\n",
        "  for child1, child2 in zip(offspring[::2], offspring[1::2]):\n",
        "    if rnd.random() < CXPB:\n",
        "      c1 = toolbox.clone(child1)\n",
        "      c2 = toolbox.clone(child2)\n",
        "      toolbox.mate(child1, child2)\n",
        "      if c1 != child1: \n",
        "        del child1.fitness.values\n",
        "      if c2 != child2: \n",
        "        del child2.fitness.values\n",
        "\n",
        "  for mutant in offspring:\n",
        "    if rnd.random() < MUTPB:\n",
        "      m1 = toolbox.clone(mutant)\n",
        "      toolbox.mutate(mutant)\n",
        "      if m1 != mutant: \n",
        "        del mutant.fitness.values\n",
        "\n",
        "  invalid_individual = [individual for individual in offspring if not individual.fitness.valid]\n",
        "  fitnesses = map(toolbox.evaluate, invalid_individual)\n",
        "\n",
        "  for individual, fitness in zip(invalid_individual, fitnesses):\n",
        "    individual.fitness.values = fitness\n",
        "\n",
        "  print (f'  Evaluated {len(invalid_individual)} individuals')\n",
        "\n",
        "  pop[:] = offspring\n",
        "  fits = [individual.fitness.values[0] for individual in pop]\n",
        "\n",
        "  length = len(pop)\n",
        "  mean = sum(fits) / length\n",
        "  sum2 = sum(x * x for x in fits)\n",
        "  std = abs(sum2 / length - mean**2)**0.5\n",
        "  best_individual = tools.selBest(pop, POPSIZE)[0]\n",
        "  print(f'Best individual is {best_individual}, {best_individual.fitness.values}')        \n",
        "  print(f'  Min: {min(fits)}')\n",
        "  print(f'  Max: {max(fits)}')\n",
        "  print(f'  Avg: {mean}')\n",
        "  print(f'  Std: {std}')\n",
        "\n",
        "print('End evolution of Logistic Regression')\n",
        "\n",
        "best_individual = tools.selBest(pop, POPSIZE)[0]\n",
        "print(f'Best individual is {best_individual}, {best_individual.fitness.values}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oVkvEROC240S"
      },
      "source": [
        "model = getModelLR(best_individual)\n",
        "Xy = getXyLR(best_individual)\n",
        "LR_columns = Xy[4]\n",
        "scaler = Xy[5]\n",
        "print(f'Selected Features: {LR_columns}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HmirS22NazOm"
      },
      "source": [
        "X_train = Xy[0]\n",
        "Y_train = Xy[1]\n",
        "X_test = Xy[2]\n",
        "Y_test = Xy[3]\n",
        "\n",
        "scores = cross_val_score(model, X_train, Y_train, cv=5).mean()\n",
        "cv_LRGA_score = scores.mean()\n",
        "print(f'LRGA CV score: {scores.mean()}')\n",
        "model.fit(X_train ,Y_train)\n",
        "print(f'Training score: {model.score(X_train, Y_train)}')\n",
        "prediction = model.predict(X_test)\n",
        "print(f'Prediction score: {(prediction == Y_test).mean()}')\n",
        "print('\\n' + classification_report(Y_test, prediction))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oXoDEoUj-pxM"
      },
      "source": [
        "2. K-Nearest Neighbor (KNN)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "grHL3y2b-pfs"
      },
      "source": [
        "def getNeighborKNN():\n",
        "  neighbor = rnd.randint(1, 20)\n",
        "\n",
        "  return neighbor\n",
        "\n",
        "def getWeightKNN():\n",
        "  weights = ['uniform', 'distance']\n",
        "  index = rnd.randint(0, len(weights) - 1)   \n",
        "  weight = weights[index]\n",
        "\n",
        "  return weight"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2rGh2Ga5bqKd"
      },
      "source": [
        "def getModelKNN(individual):\n",
        "  n_neighbors = individual[0]\n",
        "  weights = individual[1]\n",
        "\n",
        "  model = KNeighborsClassifier(n_neighbors=n_neighbors, weights=weights)\n",
        "\n",
        "  return model\n",
        "\n",
        "def getXyKNN(individual):\n",
        "  selected_columns = list(columns)\n",
        "\n",
        "  for i in range(len(individual[2:])):\n",
        "    if individual[2 + i] < 1:\n",
        "      selected_columns.remove(columns[i])\n",
        "\n",
        "  target_columns = np.append(['experimental_class'], selected_columns)\n",
        "  df = training.loc[:, target_columns].dropna()\n",
        "  X  = df.loc[:, selected_columns]\n",
        "  y = np.ravel(df.loc[:, ['experimental_class']])\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
        "  standard_scaler = preprocessing.StandardScaler().fit(X)\n",
        "  X_train = standard_scaler.transform(X_train)\n",
        "  X_test = standard_scaler.transform(X_test)\n",
        "  return [X_train, y_train, X_test, y_test, selected_columns, standard_scaler] \n",
        "\n",
        "def evaluteOneMaxKNN(individual):\n",
        "  model = getModelKNN(individual)\n",
        "  Xy = getXyKNN(individual)\n",
        "  scores = cross_val_score(model, Xy[0], Xy[1], cv=5, n_jobs=-1)\n",
        "  mean = scores.mean(),\n",
        "  \n",
        "  return mean\n",
        "\n",
        "def myMutateKNN(individual, indpb=0.05):\n",
        "  if rnd.random() < indpb:\n",
        "      individual[0] = toolbox.attribute_N_NeighborsKNN()\n",
        "\n",
        "  if rnd.random() < indpb:\n",
        "      individual[1] = toolbox.attribute_WeightsKNN()\n",
        "      \n",
        "  for i in range(len(individual[2:])):\n",
        "      if rnd.random() < indpb:\n",
        "          individual[2 + i] = toolbox.attribute_bool()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6BPcJ7OXcJVw"
      },
      "source": [
        "creator.create('FitnessMax', base.Fitness, weights=(1.0,))\n",
        "creator.create('Individual', list, fitness=creator.FitnessMax)\n",
        "\n",
        "toolbox = base.Toolbox()\n",
        "toolbox.register('attribute_bool', rnd.randint, 0, 1)\n",
        "toolbox.register('attribute_N_NeighborsKNN', getNeighborKNN)\n",
        "toolbox.register('attribute_WeightsKNN', getWeightKNN)\n",
        "\n",
        "function_sequence = [toolbox.attribute_N_NeighborsKNN, toolbox.attribute_WeightsKNN]\n",
        "\n",
        "for column in columns:\n",
        "  function_sequence.append(toolbox.attribute_bool)\n",
        "\n",
        "toolbox.register('individual', tools.initCycle, creator.Individual, function_sequence, 1)\n",
        "toolbox.register('population', tools.initRepeat, list, toolbox.individual)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XUQZXCvzcp4Y"
      },
      "source": [
        "toolbox.register('evaluate', evaluteOneMaxKNN)\n",
        "toolbox.register('mate', tools.cxTwoPoint)\n",
        "toolbox.register('mutate', myMutateKNN, indpb=0.15)\n",
        "toolbox.register('select', tools.selTournament, tournsize=3)\n",
        "rnd.seed(66)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9kmLoRzpcvUC"
      },
      "source": [
        "CXPB, MUTPB, NGEN, POPSIZE = 0.5, 0.2, 100, 100\n",
        "pop = toolbox.population(n=POPSIZE) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mDR-X8_KdJ66"
      },
      "source": [
        "print('Start evolution of K-Nearest Neighbor')\n",
        "\n",
        "fitnesses = list(map(toolbox.evaluate, pop))\n",
        "for individual, fitness in zip(pop, fitnesses):\n",
        "  individual.fitness.values = fitness\n",
        "\n",
        "print (f'  Evaluated {len(pop)} individuals')\n",
        "\n",
        "for generation in range(NGEN):\n",
        "  print(f'-- Generation {generation} --')\n",
        "\n",
        "  offspring = toolbox.select(pop, len(pop))\n",
        "  offspring = list(map(toolbox.clone, offspring))\n",
        "\n",
        "  for child1, child2 in zip(offspring[::2], offspring[1::2]):\n",
        "    if rnd.random() < CXPB:\n",
        "      c1 = toolbox.clone(child1)\n",
        "      c2 = toolbox.clone(child2)\n",
        "      toolbox.mate(child1, child2)\n",
        "      if c1 != child1: \n",
        "        del child1.fitness.values\n",
        "      if c2 != child2: \n",
        "        del child2.fitness.values\n",
        "\n",
        "  for mutant in offspring:\n",
        "    if rnd.random() < MUTPB:\n",
        "      m1 = toolbox.clone(mutant)\n",
        "      toolbox.mutate(mutant)\n",
        "      if m1 != mutant: \n",
        "        del mutant.fitness.values\n",
        "\n",
        "  invalid_individual = [individual for individual in offspring if not individual.fitness.valid]\n",
        "  fitnesses = map(toolbox.evaluate, invalid_individual)\n",
        "\n",
        "  for individual, fitness in zip(invalid_individual, fitnesses):\n",
        "    individual.fitness.values = fitness\n",
        "\n",
        "  print (f'  Evaluated {len(invalid_individual)} individuals')\n",
        "\n",
        "  pop[:] = offspring\n",
        "  fits = [individual.fitness.values[0] for individual in pop]\n",
        "\n",
        "  length = len(pop)\n",
        "  mean = sum(fits) / length\n",
        "  sum2 = sum(x * x for x in fits)\n",
        "  std = abs(sum2 / length - mean**2)**0.5\n",
        "  best_individual = tools.selBest(pop, POPSIZE)[0]\n",
        "  print(f'Best individual is {best_individual}, {best_individual.fitness.values}')        \n",
        "  print(f'  Min: {min(fits)}')\n",
        "  print(f'  Max: {max(fits)}')\n",
        "  print(f'  Avg: {mean}')\n",
        "  print(f'  Std: {std}')\n",
        "\n",
        "print('End evolution of K-Nearest Neighbor')\n",
        "\n",
        "best_individual = tools.selBest(pop, POPSIZE)[0]\n",
        "print(f'Best individual is {best_individual}, {best_individual.fitness.values}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eeosqs2pdyq-"
      },
      "source": [
        "model = getModelKNN(best_individual)\n",
        "Xy = getXyKNN(best_individual)\n",
        "KNN_columns = Xy[4]\n",
        "scaler = Xy[5]\n",
        "print(f'Selected Features: {KNN_columns}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QlbG1FFdd4cG"
      },
      "source": [
        "X_train = Xy[0]\n",
        "Y_train = Xy[1]\n",
        "X_test = Xy[2]\n",
        "Y_test = Xy[3]\n",
        "\n",
        "scores = cross_val_score(model, X_train, Y_train, cv=5).mean()\n",
        "cv_KNNGA_score = scores.mean()\n",
        "print(f'KNNGA CV score: {scores.mean()}')\n",
        "model.fit(X_train ,Y_train)\n",
        "print(f'Training score: {model.score(X_train, Y_train)}')\n",
        "prediction = model.predict(X_test)\n",
        "print(f'Prediction score: {(prediction == Y_test).mean()}')\n",
        "print('\\n' + classification_report(Y_test, prediction))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P0HzwQVadreF"
      },
      "source": [
        "3. Support Vector Machine (SVM)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Backz3_duiK"
      },
      "source": [
        "def getCSVM():\n",
        "  r = rnd.random()\n",
        "  r2 = rnd.randint(0, 2)\n",
        "  C = r + r2 + 0.000000001 \n",
        "\n",
        "  return C\n",
        "\n",
        "def getGammaSVM():\n",
        "  r = rnd.random()\n",
        "  r2 = rnd.randint(0, 3)\n",
        "  gamma = 0.000000001 + (r / (10**r2))\n",
        "\n",
        "  return gamma\n",
        "\n",
        "def getKernelSVM():\n",
        "  kernels = ['rbf', 'linear', 'sigmoid']\n",
        "  index = rnd.randint(0, len(kernels) - 1)   \n",
        "  kernel = kernels[index]\n",
        "\n",
        "  return kernel"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mKv6eF_heaKI"
      },
      "source": [
        "def getModelSVM(individual):\n",
        "  C = individual[0]\n",
        "  gamma = individual[1]\n",
        "  kernel = individual[2]\n",
        "  \n",
        "  model = SVC(kernel=kernel, C=C, gamma=gamma)\n",
        "\n",
        "  return model\n",
        "\n",
        "def getXySVM(individual):\n",
        "  selected_columns = list(columns)\n",
        "\n",
        "  for i in range(len(individual[3:])):\n",
        "    if individual[3 + i] < 1:\n",
        "      selected_columns.remove(columns[i])\n",
        "\n",
        "  target_columns = np.append(['experimental_class'], selected_columns)\n",
        "  df = training.loc[:, target_columns].dropna()\n",
        "  X  = df.loc[:, selected_columns]\n",
        "  y = np.ravel(df.loc[:, ['experimental_class']])\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
        "  standard_scaler = preprocessing.StandardScaler().fit(X)\n",
        "  X_train = standard_scaler.transform(X_train)\n",
        "  X_test = standard_scaler.transform(X_test)\n",
        "  return [X_train, y_train, X_test, y_test, selected_columns, standard_scaler] \n",
        "\n",
        "def evaluteOneMaxSVM(individual):\n",
        "  model = getModelSVM(individual)\n",
        "  Xy = getXySVM(individual)\n",
        "  scores = cross_val_score(model, Xy[0], Xy[1], cv=5, n_jobs=-1)\n",
        "  mean = scores.mean(),\n",
        "  \n",
        "  return mean\n",
        "\n",
        "def myMutateSVM(individual, indpb=0.05):\n",
        "  if rnd.random() < indpb:\n",
        "      individual[0] = toolbox.attribute_CKNN()\n",
        "\n",
        "  if rnd.random() < indpb:\n",
        "      individual[1] = toolbox.attribute_GammaKNN()\n",
        "\n",
        "  if rnd.random() < indpb:\n",
        "      individual[2] = toolbox.attribute_KernelSVM()\n",
        "      \n",
        "  for i in range(len(individual[3:])):\n",
        "      if rnd.random() < indpb:\n",
        "          individual[3 + i] = toolbox.attribute_bool()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wADW7G0Qe22s"
      },
      "source": [
        "creator.create('FitnessMax', base.Fitness, weights=(1.0,))\n",
        "creator.create('Individual', list, fitness=creator.FitnessMax)\n",
        "\n",
        "toolbox = base.Toolbox()\n",
        "toolbox.register('attribute_bool', rnd.randint, 0, 1)\n",
        "toolbox.register('attribute_CKNN', getCSVM)\n",
        "toolbox.register('attribute_GammaKNN', getGammaSVM)\n",
        "toolbox.register('attribute_KernelSVM', getKernelSVM)\n",
        "\n",
        "function_sequence = [toolbox.attribute_CKNN, toolbox.attribute_GammaKNN, toolbox.attribute_KernelSVM]\n",
        "\n",
        "for column in columns:\n",
        "  function_sequence.append(toolbox.attribute_bool)\n",
        "\n",
        "toolbox.register('individual', tools.initCycle, creator.Individual, function_sequence, 1)\n",
        "toolbox.register('population', tools.initRepeat, list, toolbox.individual)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wAbjpvf3fPER"
      },
      "source": [
        "toolbox.register('evaluate', evaluteOneMaxSVM)\n",
        "toolbox.register('mate', tools.cxTwoPoint)\n",
        "toolbox.register('mutate', myMutateSVM, indpb=0.15)\n",
        "toolbox.register('select', tools.selTournament, tournsize=3)\n",
        "rnd.seed(66)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2EOQ5FR4fYo9"
      },
      "source": [
        "CXPB, MUTPB, NGEN, POPSIZE = 0.5, 0.2, 100, 100\n",
        "pop = toolbox.population(n=POPSIZE) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FcFAE0TpfazZ"
      },
      "source": [
        "print('Start evolution of Support Vector Machine')\n",
        "\n",
        "fitnesses = list(map(toolbox.evaluate, pop))\n",
        "for individual, fitness in zip(pop, fitnesses):\n",
        "  individual.fitness.values = fitness\n",
        "\n",
        "print (f'  Evaluated {len(pop)} individuals')\n",
        "\n",
        "for generation in range(NGEN):\n",
        "  print(f'-- Generation {generation} --')\n",
        "\n",
        "  offspring = toolbox.select(pop, len(pop))\n",
        "  offspring = list(map(toolbox.clone, offspring))\n",
        "\n",
        "  for child1, child2 in zip(offspring[::2], offspring[1::2]):\n",
        "    if rnd.random() < CXPB:\n",
        "      c1 = toolbox.clone(child1)\n",
        "      c2 = toolbox.clone(child2)\n",
        "      toolbox.mate(child1, child2)\n",
        "      if c1 != child1: \n",
        "        del child1.fitness.values\n",
        "      if c2 != child2: \n",
        "        del child2.fitness.values\n",
        "\n",
        "  for mutant in offspring:\n",
        "    if rnd.random() < MUTPB:\n",
        "      m1 = toolbox.clone(mutant)\n",
        "      toolbox.mutate(mutant)\n",
        "      if m1 != mutant: \n",
        "        del mutant.fitness.values\n",
        "\n",
        "  invalid_individual = [individual for individual in offspring if not individual.fitness.valid]\n",
        "  fitnesses = map(toolbox.evaluate, invalid_individual)\n",
        "\n",
        "  for individual, fitness in zip(invalid_individual, fitnesses):\n",
        "    individual.fitness.values = fitness\n",
        "\n",
        "  print (f'  Evaluated {len(invalid_individual)} individuals')\n",
        "\n",
        "  pop[:] = offspring\n",
        "  fits = [individual.fitness.values[0] for individual in pop]\n",
        "\n",
        "  length = len(pop)\n",
        "  mean = sum(fits) / length\n",
        "  sum2 = sum(x * x for x in fits)\n",
        "  std = abs(sum2 / length - mean**2)**0.5\n",
        "  best_individual = tools.selBest(pop, POPSIZE)[0]\n",
        "  print(f'Best individual is {best_individual}, {best_individual.fitness.values}')        \n",
        "  print(f'  Min: {min(fits)}')\n",
        "  print(f'  Max: {max(fits)}')\n",
        "  print(f'  Avg: {mean}')\n",
        "  print(f'  Std: {std}')\n",
        "\n",
        "print('End evolution of Support Vector Machine')\n",
        "\n",
        "best_individual = tools.selBest(pop, POPSIZE)[0]\n",
        "print(f'Best individual is {best_individual}, {best_individual.fitness.values}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gPqNOIuFfii_"
      },
      "source": [
        "model = getModelSVM(best_individual)\n",
        "Xy = getXySVM(best_individual)\n",
        "SVM_columns = Xy[4]\n",
        "scaler = Xy[5]\n",
        "print(f'Selected Features: {SVM_columns}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hUATpsQXfoIO"
      },
      "source": [
        "X_train = Xy[0]\n",
        "Y_train = Xy[1]\n",
        "X_test = Xy[2]\n",
        "Y_test = Xy[3]\n",
        "\n",
        "scores = cross_val_score(model, X_train, Y_train, cv=5).mean()\n",
        "cv_SVMGA_score = scores.mean()\n",
        "print(f'SVMGA CV score: {scores.mean()}')\n",
        "model.fit(X_train ,Y_train)\n",
        "print(f'Training score: {model.score(X_train, Y_train)}')\n",
        "prediction = model.predict(X_test)\n",
        "print(f'Prediction score: {(prediction == Y_test).mean()}')\n",
        "print('\\n' + classification_report(Y_test, prediction))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CRKVIluwfxIA"
      },
      "source": [
        "4. Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8FS_zjt6fyeJ"
      },
      "source": [
        "def getMaxDepthDT():\n",
        "  max_depth = rnd.randint(3, 4)\n",
        "  return max_depth\n",
        "\n",
        "def getMaxFeaturesDT():\n",
        "  max_features = rnd.randint(1, 4)\n",
        "  return max_features\n",
        "\n",
        "def getMinSamplesLeafDT():\n",
        "  min_samples_leaf = rnd.randint(1, 4)\n",
        "  return min_samples_leaf\n",
        "\n",
        "def getMinSamplesSplitDT():\n",
        "  min_samples_split = rnd.randint(1, 20)\n",
        "  return min_samples_split\n",
        "\n",
        "def getCriterionDT():\n",
        "  criteria = ['gini', 'entropy']\n",
        "  index = rnd.randint(0, len(criteria) - 1)   \n",
        "  criterion = criteria[index]\n",
        "\n",
        "  return criterion"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9PuOoc6NhQVs"
      },
      "source": [
        "def getModelDT(individual):\n",
        "  max_depth = individual[0]\n",
        "  max_features = individual[1]\n",
        "  min_samples_leaf = individual[2]\n",
        "  min_samples_split = individual[3]\n",
        "  criterion = individual[4]\n",
        "  \n",
        "  model = DecisionTreeClassifier(max_depth=max_depth, max_features=max_features, min_samples_leaf=min_samples_leaf, min_samples_split=min_samples_split, criterion=criterion)\n",
        "\n",
        "  return model\n",
        "\n",
        "def getXyDT(individual):\n",
        "  selected_columns = list(columns)\n",
        "\n",
        "  for i in range(len(individual[5:])):\n",
        "    if individual[5 + i] < 1:\n",
        "      selected_columns.remove(columns[i])\n",
        "\n",
        "  target_columns = np.append(['experimental_class'], selected_columns)\n",
        "  df = training.loc[:, target_columns].dropna()\n",
        "  X  = df.loc[:, selected_columns]\n",
        "  y = np.ravel(df.loc[:, ['experimental_class']])\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
        "  standard_scaler = preprocessing.StandardScaler().fit(X)\n",
        "  X_train = standard_scaler.transform(X_train)\n",
        "  X_test = standard_scaler.transform(X_test)\n",
        "  return [X_train, y_train, X_test, y_test, selected_columns, standard_scaler]  \n",
        "\n",
        "def evaluteOneMaxDT(individual):\n",
        "  model = getModelDT(individual)\n",
        "  Xy = getXyDT(individual)\n",
        "  scores = cross_val_score(model, Xy[0], Xy[1], cv=5, n_jobs=-1)\n",
        "  mean = scores.mean(),\n",
        "  \n",
        "  return mean\n",
        "\n",
        "def myMutateDT(individual, indpb=0.05):\n",
        "  if rnd.random() < indpb:\n",
        "      individual[0] = toolbox.attribute_Max_Depth_DT()\n",
        "\n",
        "  if rnd.random() < indpb:\n",
        "      individual[1] = toolbox.attribute_Max_FeaturesDT()\n",
        "\n",
        "  if rnd.random() < indpb:\n",
        "      individual[2] = toolbox.attribute_Min_Samples_LeafDT()\n",
        "  \n",
        "  if rnd.random() < indpb:\n",
        "      individual[2] = toolbox.attribute_Min_Samples_SplitDT()\n",
        "\n",
        "  if rnd.random() < indpb:\n",
        "    individual[2] = toolbox.attribute_Min_Samples_SplitDT()\n",
        "      \n",
        "  for i in range(len(individual[5:])):\n",
        "      if rnd.random() < indpb:\n",
        "          individual[5 + i] = toolbox.attribute_bool()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-e0IjJgiS8B"
      },
      "source": [
        "creator.create('FitnessMax', base.Fitness, weights=(1.0,))\n",
        "creator.create('Individual', list, fitness=creator.FitnessMax)\n",
        "\n",
        "toolbox = base.Toolbox()\n",
        "toolbox.register('attribute_bool', rnd.randint, 0, 1)\n",
        "toolbox.register('attribute_Max_Depth_DT', getMaxDepthDT)\n",
        "toolbox.register('attribute_Max_FeaturesDT', getMaxFeaturesDT)\n",
        "toolbox.register('attribute_Min_Samples_LeafDT', getMinSamplesLeafDT)\n",
        "toolbox.register('attribute_Min_Samples_SplitDT', getMinSamplesSplitDT)\n",
        "toolbox.register('attribute_CriterionDT', getCriterionDT)\n",
        "\n",
        "function_sequence = [toolbox.attribute_Max_Depth_DT, toolbox.attribute_Max_FeaturesDT, toolbox.attribute_Min_Samples_LeafDT, toolbox.attribute_Min_Samples_SplitDT, toolbox.attribute_CriterionDT]\n",
        "\n",
        "for column in columns:\n",
        "  function_sequence.append(toolbox.attribute_bool)\n",
        "\n",
        "toolbox.register('individual', tools.initCycle, creator.Individual, function_sequence, 1)\n",
        "toolbox.register('population', tools.initRepeat, list, toolbox.individual)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "urKOevvGp-a5"
      },
      "source": [
        "toolbox.register('evaluate', evaluteOneMaxDT)\n",
        "toolbox.register('mate', tools.cxTwoPoint)\n",
        "toolbox.register('mutate', myMutateDT, indpb=0.15)\n",
        "toolbox.register('select', tools.selTournament, tournsize=3)\n",
        "rnd.seed(66)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RmhyXJ9zqHT_"
      },
      "source": [
        "CXPB, MUTPB, NGEN, POPSIZE = 0.5, 0.2, 100, 100\n",
        "pop = toolbox.population(n=POPSIZE) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rtvTaYy9qJmW"
      },
      "source": [
        "print('Start evolution of Decision Tree')\n",
        "\n",
        "fitnesses = list(map(toolbox.evaluate, pop))\n",
        "for individual, fitness in zip(pop, fitnesses):\n",
        "  individual.fitness.values = fitness\n",
        "\n",
        "print (f'  Evaluated {len(pop)} individuals')\n",
        "\n",
        "for generation in range(NGEN):\n",
        "  print(f'-- Generation {generation} --')\n",
        "\n",
        "  offspring = toolbox.select(pop, len(pop))\n",
        "  offspring = list(map(toolbox.clone, offspring))\n",
        "\n",
        "  for child1, child2 in zip(offspring[::2], offspring[1::2]):\n",
        "    if rnd.random() < CXPB:\n",
        "      c1 = toolbox.clone(child1)\n",
        "      c2 = toolbox.clone(child2)\n",
        "      toolbox.mate(child1, child2)\n",
        "      if c1 != child1: \n",
        "        del child1.fitness.values\n",
        "      if c2 != child2: \n",
        "        del child2.fitness.values\n",
        "\n",
        "  for mutant in offspring:\n",
        "    if rnd.random() < MUTPB:\n",
        "      m1 = toolbox.clone(mutant)\n",
        "      toolbox.mutate(mutant)\n",
        "      if m1 != mutant: \n",
        "        del mutant.fitness.values\n",
        "\n",
        "  invalid_individual = [individual for individual in offspring if not individual.fitness.valid]\n",
        "  fitnesses = map(toolbox.evaluate, invalid_individual)\n",
        "\n",
        "  for individual, fitness in zip(invalid_individual, fitnesses):\n",
        "    individual.fitness.values = fitness\n",
        "\n",
        "  print (f'  Evaluated {len(invalid_individual)} individuals')\n",
        "\n",
        "  pop[:] = offspring\n",
        "  fits = [individual.fitness.values[0] for individual in pop]\n",
        "\n",
        "  length = len(pop)\n",
        "  mean = sum(fits) / length\n",
        "  sum2 = sum(x * x for x in fits)\n",
        "  std = abs(sum2 / length - mean**2)**0.5\n",
        "  best_individual = tools.selBest(pop, POPSIZE)[0]\n",
        "  print(f'Best individual is {best_individual}, {best_individual.fitness.values}')        \n",
        "  print(f'  Min: {min(fits)}')\n",
        "  print(f'  Max: {max(fits)}')\n",
        "  print(f'  Avg: {mean}')\n",
        "  print(f'  Std: {std}')\n",
        "\n",
        "print('End evolution of Decision Tree')\n",
        "\n",
        "best_individual = tools.selBest(pop, POPSIZE)[0]\n",
        "print(f'Best individual is {best_individual}, {best_individual.fitness.values}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bFEoeIJiqXv-"
      },
      "source": [
        "model = getModelDT(best_individual)\n",
        "Xy = getXyDT(best_individual)\n",
        "DT_columns = Xy[4]\n",
        "scaler = Xy[5]\n",
        "print(f'Selected Features: {DT_columns}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBkmo2GVqcj3"
      },
      "source": [
        "X_train = Xy[0]\n",
        "Y_train = Xy[1]\n",
        "X_test = Xy[2]\n",
        "Y_test = Xy[3]\n",
        "\n",
        "scores = cross_val_score(model, X_train, Y_train, cv=5).mean()\n",
        "cv_DTGA_score = scores.mean()\n",
        "print(f'DTGA CV score: {scores.mean()}')\n",
        "model.fit(X_train ,Y_train)\n",
        "print(f'Training score: {model.score(X_train, Y_train)}')\n",
        "prediction = model.predict(X_test)\n",
        "print(f'Prediction score: {(prediction == Y_test).mean()}')\n",
        "print('\\n' + classification_report(Y_test, prediction))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}